{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nandini11122004/Analog_automation/blob/main/BISTM_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHLUZcaxPwoR",
        "outputId": "4ed9fc2a-cf78-4d4e-f18d-90a009049e1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 3.2212\n",
            "Epoch 2/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1582 - loss: 3.2062\n",
            "Epoch 3/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2616 - loss: 3.1840\n",
            "Epoch 4/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5491 - loss: 3.1574\n",
            "Epoch 5/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5596 - loss: 3.1229\n",
            "Epoch 6/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5466 - loss: 3.0541\n",
            "Epoch 7/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3603 - loss: 2.9178\n",
            "Epoch 8/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4962 - loss: 2.5379\n",
            "Epoch 9/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4437 - loss: 2.1778\n",
            "Epoch 10/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4927 - loss: 1.9141\n",
            "Epoch 11/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6721 - loss: 1.6128\n",
            "Epoch 12/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5725 - loss: 1.3306\n",
            "Epoch 13/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6893 - loss: 1.1226\n",
            "Epoch 14/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7907 - loss: 0.9392\n",
            "Epoch 15/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7443 - loss: 0.9108\n",
            "Epoch 16/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8495 - loss: 0.7447\n",
            "Epoch 17/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8073 - loss: 0.6375\n",
            "Epoch 18/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6594 - loss: 0.6605\n",
            "Epoch 19/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8785 - loss: 0.5781\n",
            "Epoch 20/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8227 - loss: 0.4424\n",
            "Epoch 21/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8676 - loss: 0.4380\n",
            "Epoch 22/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8467 - loss: 0.4741\n",
            "Epoch 23/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8028 - loss: 0.4210\n",
            "Epoch 24/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8706 - loss: 0.3845\n",
            "Epoch 25/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8477 - loss: 0.4073\n",
            "Epoch 26/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8709 - loss: 0.3289\n",
            "Epoch 27/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8989 - loss: 0.3431\n",
            "Epoch 28/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7959 - loss: 0.3304\n",
            "Epoch 29/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8006 - loss: 0.3718\n",
            "Epoch 30/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8357 - loss: 0.3514\n",
            "Epoch 31/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8065 - loss: 0.3451\n",
            "Epoch 32/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8519 - loss: 0.3054\n",
            "Epoch 33/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8635 - loss: 0.2561\n",
            "Epoch 34/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8874 - loss: 0.2794\n",
            "Epoch 35/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8931 - loss: 0.2555\n",
            "Epoch 36/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8867 - loss: 0.2178\n",
            "Epoch 37/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8819 - loss: 0.2212\n",
            "Epoch 38/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8507 - loss: 0.3012\n",
            "Epoch 39/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7646 - loss: 0.3272\n",
            "Epoch 40/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8539 - loss: 0.3402\n",
            "Epoch 41/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9022 - loss: 0.1898\n",
            "Epoch 42/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9025 - loss: 0.2405\n",
            "Epoch 43/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9135 - loss: 0.2022\n",
            "Epoch 44/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9105 - loss: 0.2204\n",
            "Epoch 45/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8558 - loss: 0.3018\n",
            "Epoch 46/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8580 - loss: 0.2695\n",
            "Epoch 47/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9242 - loss: 0.2369\n",
            "Epoch 48/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9281 - loss: 0.2383\n",
            "Epoch 49/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9002 - loss: 0.1740\n",
            "Epoch 50/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8297 - loss: 0.2497\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a243de04b50>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Layer, Flatten\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load component dictionary from file\n",
        "import pandas as pd\n",
        "\n",
        "# Circuit categories and their expected component context\n",
        "circuit_data = {\n",
        "    \"amplifier\": [\n",
        "        [\"Vdd\", \"Vin\", \"R\", \"Q\", \"Cshunt\"],\n",
        "        [\"Voltage Supply\", \"Voltage Input\", \"Resistor\", \"NPN Transistor\", \"Capacitor Shunt\"]\n",
        "    ],\n",
        "    \"oscillator\": [\n",
        "        [\"Vdd\", \"L\", \"C\", \"Q\", \"R\"],\n",
        "        [\"Voltage Supply\", \"Inductor\", \"Capacitor\", \"PNP Transistor\", \"Resistor\"]\n",
        "    ],\n",
        "    \"rectifier\": [\n",
        "        [\"Vin\", \"D\", \"R\", \"C\"],\n",
        "        [\"Voltage Input\", \"Diode\", \"Resistor\", \"Capacitor\"]\n",
        "    ],\n",
        "    \"regulator\": [\n",
        "        [\"Vin\", \"Vout\", \"R\", \"C\", \"IC\"],\n",
        "        [\"Voltage Input\", \"Voltage Output\", \"Resistor\", \"Capacitor\", \"Integrated Circuit\"]\n",
        "    ],\n",
        "    \"filter1\": [\n",
        "        [\"Vin\", \"C\", \"L\", \"R\"],\n",
        "        [\"Voltage Input\", \"Capacitor\", \"Inductor\", \"Resistor\"]\n",
        "    ],\n",
        "    \"filter2\": [\n",
        "        [\"XU\", \"R\", \"C\", \"Vn\", \"Vp\", \"Vin\"],\n",
        "        [\"Regulator Integrated Circuit\", \"Resistor\", \"Capacitor\", \"Negative Voltage\", \"Positive Voltage\", \"Voltage Input\"]\n",
        "    ],\n",
        "    \"current_mirror\": [\n",
        "        [\"V\", \"I\", \"M\", \"M\", \"R\", \"nmos\"],\n",
        "        [\"Voltage Source\", \"Current Source\", \"MOSFET\", \"MOSFET\", \"Resistor\", \"MOSFET\"]\n",
        "    ],\n",
        "    \"voltage_regulator\": [\n",
        "        [\"XU\", \"R\", \"C\", \"R\", \"Vin\", \"Vin\", \"Vout\"],\n",
        "        [\"Regulator Integrated Circuit\", \"Resistor\", \"Capacitor\", \"Resistor\", \"Voltage Input\", \"Voltage Input\", \"Voltage Output\"]\n",
        "    ],\n",
        "    \"buck_converter\": [\n",
        "        [\"Vin\", \"L\", \"C\", \"D\", \"Q\"],\n",
        "        [\"Voltage Input\", \"Inductor\", \"Capacitor\", \"Diode\", \"MOSFET\"]\n",
        "    ],\n",
        "    \"boost_converter\": [\n",
        "        [\"Vin\", \"L\", \"C\", \"D\", \"Q\"],\n",
        "        [\"Voltage Input\", \"Inductor\", \"Capacitor\", \"Diode\", \"MOSFET\"]\n",
        "    ],\n",
        "    \"buck_boost_converter\": [\n",
        "        [\"Vin\", \"L\", \"C\", \"D\", \"Q\"],\n",
        "        [\"Voltage Input\", \"Inductor\", \"Capacitor\", \"Diode\", \"MOSFET\"]\n",
        "    ],\n",
        "\n",
        "    \"pll\": [\n",
        "        [\"Vco\", \"PFD\", \"Loop_Filter\", \"Divider\"],\n",
        "        [\"Voltage Controlled Oscillator\", \"Phase Frequency Detector\", \"Loop Filter\", \"Frequency Divider\"]\n",
        "    ],\n",
        "    \"mixer\": [\n",
        "        [\"RF\", \"LO\", \"IF\", \"Q\"],\n",
        "        [\"Radio Frequency Input\", \"Local Oscillator\", \"Intermediate Frequency Output\", \"Transistor\"]\n",
        "    ],\n",
        "    \"modulator\": [\n",
        "        [\"Vin\", \"Vout\", \"Q\", \"C\", \"R\"],\n",
        "        [\"Voltage Input\", \"Voltage Output\", \"Transistor\", \"Capacitor\", \"Resistor\"]\n",
        "    ],\n",
        "    \"demodulator\": [\n",
        "        [\"Vin\", \"D\", \"C\", \"R\"],\n",
        "        [\"Voltage Input\", \"Diode\", \"Capacitor\", \"Resistor\"]\n",
        "    ],\n",
        "    # Additional Circuits\n",
        "    \"digital_buffer\": [\n",
        "        [\"Vin\", \"Vout\", \"IC\"],\n",
        "        [\"Voltage Input\", \"Voltage Output\", \"Buffer IC\"]\n",
        "    ],\n",
        "\n",
        "    \"rf_amplifier\": [\n",
        "        [\"Vin\", \"Vout\", \"Q\", \"L\", \"C\"],\n",
        "        [\"RF Input\", \"RF Output\", \"Transistor\", \"Inductor\", \"Capacitor\"]\n",
        "    ],\n",
        "    \"log_amplifier\": [\n",
        "        [\"Vin\", \"Vout\", \"OpAmp\", \"D\"],\n",
        "        [\"Voltage Input\", \"Voltage Output\", \"Operational Amplifier\", \"Diode\"]\n",
        "    ],\n",
        "    \"precision_rectifier\": [\n",
        "        [\"Vin\", \"Vout\", \"OpAmp\", \"D\"],\n",
        "        [\"Voltage Input\", \"Voltage Output\", \"Operational Amplifier\", \"Diode\"]\n",
        "    ],\n",
        "    \"comparator\": [\n",
        "        [\"Vin+\", \"Vin-\", \"Vout\", \"OpAmp\"],\n",
        "        [\"Non-Inverting Input\", \"Inverting Input\", \"Voltage Output\", \"Operational Amplifier\"]\n",
        "    ],\n",
        "    \"frequency_synthesizer\": [\n",
        "        [\"VCO\", \"PLL\", \"Mixer\", \"Divider\"],\n",
        "        [\"Voltage Controlled Oscillator\", \"Phase-Locked Loop\", \"Mixer\", \"Frequency Divider\"]\n",
        "    ],\n",
        "    \"rf_mixer\": [\n",
        "        [\"RF\", \"LO\", \"IF\", \"Q\", \"D\"],\n",
        "        [\"Radio Frequency Input\", \"Local Oscillator\", \"Intermediate Frequency Output\", \"Transistor\", \"Diode\"]\n",
        "    ],\n",
        "    \"led_driver\": [\n",
        "        [\"Vin\", \"LED\", \"R\", \"Q\"],\n",
        "        [\"Voltage Input\", \"Light Emitting Diode\", \"Resistor\", \"Transistor\"]\n",
        "    ],\n",
        "    \"motor_driver\": [\n",
        "        [\"Vin\", \"Motor\", \"H-Bridge\", \"PWM\"],\n",
        "        [\"Voltage Input\", \"Motor\", \"H-Bridge Circuit\", \"Pulse Width Modulation\"]\n",
        "    ],\n",
        "    \"delta_sigma_modulator\": [\n",
        "        [\"Vin\", \"Vout\", \"Integrator\", \"Comparator\", \"D Flip-Flop\"],\n",
        "        [\"Voltage Input\", \"Voltage Output\", \"Integrator Circuit\", \"Comparator\", \"D-Type Flip-Flop\"]\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "# Tokenization\n",
        "#frequency based tokenization\n",
        "# Step 1: Extract unique components\n",
        "all_components = list(set(comp for variations in circuit_data.values() for components in variations for comp in components))\n",
        "\n",
        "# Step 2: Shuffle components randomly\n",
        "random.shuffle(all_components)\n",
        "\n",
        "# Step 3: Assign random indices to each component (ensuring uniqueness)\n",
        "random_token_map = {comp: idx + 1 for idx, comp in enumerate(all_components)}  # +1 to avoid index 0 (used for padding)\n",
        "\n",
        "# Step 4: Find maximum sequence length\n",
        "max_length = max(len(components) for variations in circuit_data.values() for components in variations)\n",
        "\n",
        "# Step 5: Convert components to token sequences\n",
        "X = [[random_token_map[comp] for comp in components] for variations in circuit_data.values() for components in variations]\n",
        "\n",
        "# Step 6: Pad sequences\n",
        "X = pad_sequences(X, maxlen=max_length, padding='post')\n",
        "\n",
        "# Step 7: Define vocabulary size\n",
        "vocab_size = len(random_token_map) + 1  # Include 0 for padding\n",
        "\n",
        "\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_labels = [label for label, variations in circuit_data.items() for _ in variations]\n",
        "y = label_encoder.fit_transform(y_labels)\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=len(set(y_labels)))\n",
        "\n",
        "# Define Attention Layer\n",
        "class AttentionLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
        "                                 initializer=\"glorot_uniform\", trainable=True)\n",
        "        self.b = self.add_weight(name=\"att_bias\", shape=(1,), initializer=\"zeros\", trainable=True)\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "      e = tf.nn.tanh(tf.tensordot(x, self.W, axes=1) + self.b)\n",
        "      a = tf.nn.softmax(e / 0.5, axis=1)  # Divide by 0.5 to reduce overconfidence\n",
        "      weighted_sum = tf.reduce_sum(x * a, axis=1)\n",
        "      return weighted_sum, a\n",
        "\n",
        "input_layer = Input(shape=(max_length,))\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=128, embeddings_regularizer=tf.keras.regularizers.l2(1e-5))(input_layer)\n",
        "\n",
        "# Bi-LSTM Layer\n",
        "bi_lstm = Bidirectional(LSTM(64, return_sequences=True))(embedding_layer)\n",
        "\n",
        "# Get both the weighted sum and attention scores\n",
        "weighted_sum, attention_scores = AttentionLayer(name=\"attention_layer\")(bi_lstm)\n",
        "\n",
        "\n",
        "# Classification layer\n",
        "output_layer = Dense(len(set(y_labels)), activation=\"softmax\")(weighted_sum)\n",
        "\n",
        "# Define model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=50, batch_size=4, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_circuit(components):\n",
        "    # Convert components to tokenized sequence using the randomized token map\n",
        "    seq = [[random_token_map[comp] for comp in components if comp in random_token_map]]\n",
        "\n",
        "    # Pad sequence\n",
        "    seq_padded = pad_sequences(seq, maxlen=max_length, padding='post')\n",
        "\n",
        "    # Predict probabilities\n",
        "    probabilities = model.predict(seq_padded)[0]\n",
        "\n",
        "    # Convert NumPy types to Python types for JSON compatibility\n",
        "    circuit_probabilities = {str(label_encoder.inverse_transform([i])[0]): float(prob) for i, prob in enumerate(probabilities)}\n",
        "\n",
        "    # Sort probabilities in descending order and get the top 5\n",
        "    top_5 = sorted(circuit_probabilities.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "\n",
        "    return top_5\n",
        "\n",
        "# Example: Classify a new circuit\n",
        "new_components = [\"Vin\", \"D\", \"R\"]\n",
        "top_5_probabilities = classify_circuit(new_components)\n",
        "\n",
        "# Print top 5 predictions\n",
        "for circuit, prob in top_5_probabilities:\n",
        "    print(f\"{circuit}: {prob:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "C3KkXZuzYy0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f950326d-118d-4465-ddac-c27e8bf35628"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step\n",
            "rectifier: 0.9403\n",
            "demodulator: 0.0247\n",
            "led_driver: 0.0163\n",
            "filter1: 0.0048\n",
            "modulator: 0.0044\n"
          ]
        }
      ]
    }
  ]
}